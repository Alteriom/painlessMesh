# Testing Agent

## Overview

The Testing Agent is a specialized Copilot assistant for C++ unit testing with Catch2 in the painlessMesh project. It helps generate comprehensive test suites, debug test failures, and ensure code quality through automated testing.

## Purpose

Assist developers in creating and maintaining high-quality tests by:
- Generating Catch2 test cases automatically
- Providing test debugging assistance
- Ensuring comprehensive test coverage
- Validating package serialization
- Running and analyzing test results
- Maintaining test infrastructure

## Activation

### In VS Code Copilot Chat

```
@testing-agent Generate tests for my GPS package
@testing-agent Why is my test failing with Approx errors?
@testing-agent How do I test JSON serialization?
```

### Via Copilot Agents Configuration

The agent is automatically available when you open this repository in VS Code with GitHub Copilot enabled.

## Capabilities

### 1. Test Generation

**What the agent generates:**
- Complete Catch2 test files
- SCENARIO-based test suites
- GIVEN/WHEN/THEN BDD-style tests
- Edge case testing
- Error condition testing
- Serialization validation

**Test types:**
- Package serialization tests
- JSON conversion tests
- Variant conversion tests
- Edge case validation
- Error handling tests

### 2. Test Debugging

**Debugging assistance:**
- Analyzing test failures
- Explaining Catch2 assertions
- Fixing floating-point comparisons
- Resolving JSON serialization issues
- Identifying test dependencies

### 3. Test Infrastructure

**Infrastructure support:**
- CMakeLists.txt integration
- Test runner configuration
- Catch2 framework usage
- Test utilities and helpers
- CI/CD test integration

## Usage Examples

### Example 1: Generate Package Tests

**Query:**
```
@testing-agent Create comprehensive tests for my GPSPackage with latitude, longitude, and altitude fields
```

**Response includes:**
- Complete test file with proper structure
- Serialization tests (to/from JSON)
- Variant conversion tests
- Edge case tests (boundary values)
- Special character handling
- Type validation

### Example 2: Debug Test Failure

**Query:**
```
@testing-agent My test is failing with "REQUIRE( pkg.temperature == 23.5 ) with expansion: 23.500001 == 23.5"
```

**Response includes:**
- Explanation of floating-point precision
- How to use Catch2::Approx
- Epsilon configuration for precision
- Margin vs epsilon differences
- Best practices for numeric comparison

### Example 3: Test Error Conditions

**Query:**
```
@testing-agent How do I test that my package handles invalid JSON gracefully?
```

**Response includes:**
- Invalid JSON test scenarios
- Missing field handling
- Type mismatch validation
- Default value verification
- Error recovery patterns

## Test Generation Patterns

### Package Serialization Test Template

```cpp
#define CATCH_CONFIG_MAIN
#include "catch2/catch.hpp"
#include "Arduino.h"
#include "catch_utils.hpp"
#include "examples/alteriom/your_package.hpp"

using namespace alteriom;
using namespace painlessmesh;

SCENARIO("YourPackage serialization works correctly") {
    GIVEN("A YourPackage with test data") {
        auto pkg = YourPackage();
        pkg.from = 12345;
        pkg.field1 = 42;
        pkg.field2 = "test_value";
        
        REQUIRE(pkg.type == EXPECTED_TYPE_ID);
        
        WHEN("Converting it to and from Variant") {
            auto var = protocol::Variant(&pkg);
            auto pkg2 = var.to<YourPackage>();
            
            THEN("Should result in the same values") {
                REQUIRE(pkg2.from == pkg.from);
                REQUIRE(pkg2.field1 == pkg.field1);
                REQUIRE(pkg2.field2 == pkg.field2);
            }
        }
        
        WHEN("Converting to JSON and back") {
            DynamicJsonDocument doc(1024);
            JsonObject obj = doc.to<JsonObject>();
            obj = pkg.addTo(std::move(obj));
            
            auto pkg2 = YourPackage(obj);
            
            THEN("JSON serialization preserves values") {
                REQUIRE(pkg2.field1 == pkg.field1);
                REQUIRE(String(pkg2.field2) == String(pkg.field2));
            }
        }
    }
}
```

### Edge Case Testing Pattern

```cpp
SCENARIO("YourPackage handles edge cases") {
    GIVEN("A package with boundary values") {
        auto pkg = YourPackage();
        pkg.uint32Field = UINT32_MAX;
        pkg.uint8Field = UINT8_MAX;
        pkg.stringField = "";
        
        WHEN("Serializing max values") {
            auto var = protocol::Variant(&pkg);
            auto pkg2 = var.to<YourPackage>();
            
            THEN("Max values are preserved") {
                REQUIRE(pkg2.uint32Field == UINT32_MAX);
                REQUIRE(pkg2.uint8Field == UINT8_MAX);
            }
        }
        
        WHEN("Serializing empty strings") {
            auto var = protocol::Variant(&pkg);
            auto pkg2 = var.to<YourPackage>();
            
            THEN("Empty strings are preserved") {
                REQUIRE(pkg2.stringField == "");
            }
        }
    }
    
    GIVEN("A package with special characters") {
        auto pkg = YourPackage();
        pkg.stringField = "Test\"with\nspecial\tchars";
        
        WHEN("Converting to JSON") {
            DynamicJsonDocument doc(1024);
            JsonObject obj = doc.to<JsonObject>();
            obj = pkg.addTo(std::move(obj));
            
            auto pkg2 = YourPackage(obj);
            
            THEN("Special characters are escaped correctly") {
                REQUIRE(pkg2.stringField == pkg.stringField);
            }
        }
    }
}
```

## Best Practices Enforced

### Test Structure
- ✅ Use SCENARIO for test suites
- ✅ Use GIVEN/WHEN/THEN for BDD style
- ✅ One logical test per WHEN/THEN block
- ✅ Clear, descriptive test names
- ✅ Comprehensive edge case coverage

### Assertions
- ✅ Use REQUIRE for critical checks
- ✅ Use Approx for floating-point comparisons
- ✅ Test both success and failure paths
- ✅ Validate all fields after serialization
- ✅ Check type IDs explicitly

### Code Quality
- ✅ Include all necessary headers
- ✅ Use proper namespaces
- ✅ Clean, readable test code
- ✅ Avoid test interdependencies
- ✅ Fast-running tests

### Coverage Goals
- ✅ All package types tested
- ✅ Serialization to/from JSON
- ✅ Variant conversions
- ✅ Edge cases (empty, max values)
- ✅ Error conditions
- ✅ Special characters

## Knowledge Sources

The agent has deep knowledge of:

1. **Testing Instructions**: `.github/instructions/testing.instructions.md`
   - Test patterns
   - Best practices
   - Common pitfalls

2. **Test Files**: `test/catch/`
   - Existing test examples
   - Test utilities
   - Helper functions

3. **Catch2 Framework**
   - Assertion macros
   - BDD syntax
   - Test organization

4. **Package System**: `src/painlessmesh/plugin.hpp`
   - Package structure
   - Serialization interface
   - Type system

5. **Build System**: `CMakeLists.txt`
   - Test discovery
   - Build configuration
   - Test execution

## Common Testing Scenarios

### Scenario 1: New Package Testing

**Situation**: Developer creates a new Alteriom package

**Agent helps with:**
1. Generate complete test file
2. Cover all fields and methods
3. Include edge cases
4. Set up proper assertions
5. Validate serialization

### Scenario 2: Test Failure Resolution

**Situation**: Test fails with unclear error message

**Agent helps with:**
1. Interpret Catch2 output
2. Identify root cause
3. Suggest fixes
4. Explain best practices
5. Prevent similar issues

### Scenario 3: Test Coverage Improvement

**Situation**: Need to increase test coverage

**Agent helps with:**
1. Identify untested code paths
2. Generate missing tests
3. Add edge case scenarios
4. Improve assertions
5. Validate error handling

### Scenario 4: Test Refactoring

**Situation**: Tests need restructuring or updating

**Agent helps with:**
1. Modernize test syntax
2. Improve test organization
3. Reduce duplication
4. Enhance readability
5. Update for API changes

## Running Tests

### Build and Run All Tests

```bash
# Configure and build
cmake -G Ninja .
ninja

# Run all tests
run-parts --regex catch_ bin/

# Or run individual tests
./bin/catch_alteriom_packages
./bin/catch_protocol
./bin/catch_router
```

### Run Specific Tests

```bash
# Run specific scenario
./bin/catch_alteriom_packages "[scenario_name]"

# Run with verbose output
./bin/catch_alteriom_packages -s

# List all tests
./bin/catch_alteriom_packages -l

# Run tests matching pattern
./bin/catch_alteriom_packages "[package]*"
```

### Debug Test Failures

```bash
# Run with success output
./bin/catch_alteriom_packages -s

# Run specific test with details
./bin/catch_alteriom_packages -s "[test_name]"

# Get test statistics
./bin/catch_alteriom_packages -r compact
```

## Common Testing Issues

### Issue 1: Floating-Point Comparison Failures

**Problem**: `REQUIRE(value == 23.5)` fails with `23.500001 == 23.5`

**Solution**:
```cpp
// ❌ Don't use direct comparison
REQUIRE(pkg.temperature == 23.5);

// ✅ Use Approx
REQUIRE(pkg.temperature == Approx(23.5));

// ✅ Specify epsilon for precision
REQUIRE(pkg.latitude == Approx(37.7749).epsilon(0.0001));
```

### Issue 2: String Comparison Issues

**Problem**: TSTRING comparisons fail

**Solution**:
```cpp
// ❌ May fail with TSTRING
REQUIRE(pkg.textField == "expected");

// ✅ Convert to String
REQUIRE(String(pkg.textField) == "expected");
```

### Issue 3: JSON Buffer Too Small

**Problem**: Serialization truncates data

**Solution**:
```cpp
// ❌ Buffer too small
DynamicJsonDocument doc(128);

// ✅ Calculate proper size
DynamicJsonDocument doc(1024); // Or use pkg.jsonObjectSize()
```

### Issue 4: Test Order Dependencies

**Problem**: Tests pass individually but fail together

**Solution**:
- Ensure tests are independent
- Reset state in each GIVEN block
- Don't rely on global state
- Use fresh objects per test

## Integration with Other Agents

The Testing Agent works well with:

### Mesh Development Agent
- **When**: After creating new packages
- **Why**: Ensure correct implementation
- **How**: "@mesh-dev-agent create package" → "@testing-agent test it"

### Documentation Agent
- **When**: Tests need documentation
- **Why**: Explain test patterns
- **How**: "@docs-agent document my test strategy"

### Release Agent
- **When**: Before releases
- **Why**: Validate all tests pass
- **How**: "@release-agent check if tests pass"

## Advanced Testing Techniques

### Parameterized Tests

Test multiple scenarios with one test structure:

```cpp
SCENARIO("Package handles various numeric ranges") {
    auto testValues = {0, 1, 100, 1000, UINT32_MAX};
    
    for (auto value : testValues) {
        GIVEN("Package with value " + std::to_string(value)) {
            // Test implementation
        }
    }
}
```

### Custom Matchers

Create reusable test conditions:

```cpp
// In catch_utils.hpp
bool isValidGPSCoordinate(double lat, double lon) {
    return lat >= -90 && lat <= 90 && 
           lon >= -180 && lon <= 180;
}

// In test
REQUIRE(isValidGPSCoordinate(pkg.latitude, pkg.longitude));
```

### Performance Testing

Measure serialization performance:

```cpp
SCENARIO("Serialization performance") {
    GIVEN("A large number of packages") {
        auto start = std::chrono::high_resolution_clock::now();
        
        for (int i = 0; i < 1000; i++) {
            // Serialize package
        }
        
        auto end = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
        
        REQUIRE(duration.count() < 1000); // Should take < 1 second
    }
}
```

## Troubleshooting

### Agent Not Generating Correct Tests

**Issue**: Generated tests don't match package structure

**Solutions**:
- Provide complete package definition
- Mention specific fields to test
- Reference existing test files as examples
- Specify edge cases needed

### Tests Won't Compile

**Issue**: Generated tests have compilation errors

**Solutions**:
- Check include paths
- Verify namespace usage
- Ensure proper CMake configuration
- Update test utilities if needed

### Tests Pass Locally But Fail in CI

**Issue**: Tests work on development machine but not in CI

**Solutions**:
- Check platform differences
- Verify dependency versions
- Review CI test output carefully
- Ensure deterministic tests

## Related Resources

### Documentation
- [Testing Instructions](.github/instructions/testing.instructions.md)
- [Catch2 Documentation](https://github.com/catchorg/Catch2)
- [Development Guide](.github/README-DEVELOPMENT.md)

### Examples
- `test/catch/catch_alteriom_packages.cpp` - Package test examples
- `test/catch/catch_protocol.cpp` - Protocol test examples
- `test/catch/catch_utils.hpp` - Test utilities

### Other Agents
- [Mesh Development Agent](mesh-dev-agent.md) - Package development
- [Documentation Agent](docs-agent.md) - Test documentation
- [Release Agent](release-agent.md) - Pre-release validation

---

**Last Updated**: November 11, 2024  
**Agent Version**: 1.0  
**Maintained By**: AlteriomPainlessMesh Team
